<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>AVL</title>

    <link href="./static/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Kaushan+Script|Droid+Serif:400,700,400italic,700italic|Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous">
	<link rel="icon" href="./images/GES-X_logo.PNG?version=1" type="image/x-icon">

    <!-- Custom styles for this template -->
    <link href="./css/agency.css" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bootstrap.min.css">
    <style>
        /* Custom styles for the carousel controls */
        .carousel-control-prev, .carousel-control-next {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            background-color: rgba(0, 0, 0, 0.5);
            display: flex;
            justify-content: center;
            align-items: center;
            top: 50%;
            transform: translateY(-50%);
            color: white;
            font-size: 24px;
            text-decoration: none;
        }

        .carousel-control-prev {
            left: 20px;
        }

        .carousel-control-next {
            right: 20px;
        }
    </style>
    
  </head>

  <body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav", style = "background-color: rgba(159, 193, 213, 0.779)">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top"> <img style="width:15em;" src="./static/images/logo.png" alt="Logo"></a>
          <!-- <p style="width:8em; font-family: 'Roboto Slab', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 15px; font-style: italic; color: white; margin-top:-27px; margin-left:3px">Toward Coherent Co-speech 3D
          Gesture Generation in the Wild</p> -->
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fa fa-bars fa-2x" aria-hidden="true"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
            <li class="nav-item" style="font-size: 110%">
              <a class="nav-link js-scroll-trigger" href="#dataset">Dataset</a>
            </li>
            <li class="nav-item" style="font-size: 110%">
              <a class="nav-link js-scroll-trigger" href="#model">Model</a>
            </li>
            <li class="nav-item" style="font-size: 110%">
              <a class="nav-link js-scroll-trigger" href="#results">results</a>
            </li>
			      <li class="nav-item" style="font-size: 110%">
              <a class="nav-link js-scroll-trigger" href="#experiments">experiments</a>
            </li>

          </ul>
        </div>
      </div>
    </nav>


    <!-- Header -->
    <header class="masthead">
      <div class="container">
            <div class="row align-items-center intro-text" style="margin-top: 100px">
              <!-- <div class="intro-lead-in" style="margin-left: 80px">CoCoGesture</div> -->
              <!-- <video controls class="d-block w-100">
                <source src="./videos/ges_demo.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video> -->
              <div class="intro-lead-in"><h2>Audio-Visual Understanding: Towards Fine-Grained Audio-Visual Learning with Region-Aware Sound Source Understanding</h2></div>
              <div class="w-50">
                  <p style="color: rgb(171, 171, 171)">  We newly define a fine-grained AudioVisual Learning task, termed Audio-Visual Understanding (AVU), which aims at achieving region-aware, frame-level, and high-quality sound source understanding.
                    To support this goal, we newly construct two corresponding datasets: fine-grained Music (f-Music) and fine-grained Lifescene (f-Lifescene).
                    Moreover, we propose AVUFormer, an Audio-Visual Understanding TransFormer benchmark that facilitates both the sound source segmentation and sound region description with a multi-model input and multi-model output Transformer architecture.
                  </p>
              </div>
              <div class="w-50">
                <img style="float: right; width: 90%" src="./static/images/AVUTask.png" alt="">
              </div>
        </div>
      </div>
    </header>

<!-- Dataset -->
<section class="bg-transparent" id="dataset">
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center" style="margin-bottom: -30px">
        <h2 class="section-heading" style="color: rgb(90, 90, 90); margin-top: 90px">Datasets</h2>
        <h6 class="section-subheading" style="color: rgb(171, 171, 171);margin-bottom: 30px">Dataset Analysis and Statistics</h6>
      </div>
    </div>

    <div class="row">
      <!-- news column -->
      <div class="col-md-7">
        <h4 class="service-heading">Basic informations</h4>
        <ul class="text-muted">
          <li class="text-muted">we newly construct two corresponding datasets: fine-grained Music <strong>(f-Music)</strong> and fine-grained Lifescene <strong>(f-Lifescene)</strong>.</li>
          <li class="text-muted">containing annotated sound source masks and frame-by-frame textual descriptions</li>
          <li class="text-muted">f-Music focuses on music scenes with complex instrument mixing and background noise,f-Lifescene includes diverse sounding objects in life scenarios.</li>
        </ul>
      </div>
      <!-- characteristics column -->
      <div class="col-md-5">
        <h4 class="service-heading">Basic statistics</h4>
        <ul class="text-muted">
          <li class="text-muted">f-Music dataset includes 3,976 samples across 22 scene types</li>
          <li class="text-muted">f-Lifescene dataset contains 6,156 samples across 61 types</li>
        </ul>
      </div>
    </div>

  </br>
	<h5 class="section-subheading" style="text-align:left; margin-top:20px; color: rgb(100, 100, 100)">Statistics of sounding scene category from two datasets</h5>
	    <div class="row justify-content-md-center text-center">
      <div class="col-md centered" style="padding:1rem; margin-top:20px; ">
        <img src="./static/images/categories.png" style="width: 60%" class="img-responsive"/> 
      </div>
      </div>

  </br>
	<h5 class="section-subheading" style="text-align:left; margin-top:20px; color: rgb(100, 100, 100)">Data annotation process and labeling system</h5>
	    <div class="row justify-content-md-center text-center">
      <div class="col-md centered" style="padding:1rem; margin-top:20px; ">
        <img src="./static/images/process_and_system.png" style="width: 90%" class="img-responsive"/> 
      </div>
      <p class="text-muted" style="text-align:left; margin-left:15px"> 
        In this system, the video data is first uploaded into the system. Then the SAM model is used to
        obtain the initial masks. Based on the initial masks, the TAM is used to gain the frame-level video
        masks. Finally, the masked region of the frame-level images are fed into the Chat-Univi to get the
        region-aware descriptions.
      </p>
      </div>

  </div>
</section>

<!-- Model -->
<section id="model">
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center" style="margin-bottom: -30px">
        <h2 class="section-heading" style="color: rgb(90, 90, 90); margin-top: 60px">Model</h2>
        <h6 class="section-subheading" style="color: rgb(171, 171, 171)">Our framework AVUFormer and key modules </h6>
      </div>
    </div>

  <!-- <h5 class="section-subheading" style="text-align:left; color: rgb(100, 100, 100); margin-top: 20px">Task Introduction</h5>
    <div class="row text-center">
      <p class="text-muted" style="text-align:left; margin-left:15px"> 
        In our work, we focus on the task of vivid and diverse co-speech 3D gesture generation from in-the-wild human voices.<br> Details about our task are shown in the figure below:
      </p>
    </div>
    <div class="col-md centered" style="padding:1rem; margin-top: 10px; ">
      <img src="./images/tip-teaser_04_09_2025.pdf" style="width: 100%" class="img-responsive"/> 
    </div> -->


  </br>
	<h5 class="section-subheading" style="text-align:left; margin-top:20px; color: rgb(100, 100, 100)">AVUFormer Framework</h5>
	    <div class="row justify-content-md-center text-center">
      <div class="col-md centered" style="padding:1rem; margin-top:20px; ">
        <img src="./static/images/AVUFormer.png" style="width: 100%" class="img-responsive"/> 
      </div>
      <p class="text-muted" style="text-align:left; margin-left:15px"> 
      <strong>AVUFormer</strong>: fine-grainied Audio-Visual Understanding Benchmark. In the left of this architecture, the audio and video are fed into the encoders and mapped to the tokens. Then the multi-modal
        features are fused with the attention mechanism. Next, the previous features are integrated into task decoders for mask and description generation.
      </p>
      </div>
	
	</br>
	<h5 class="section-subheading" style="text-align:left; margin-top:20px; color: rgb(100, 100, 100)">Multi-Modality Integration (MMI)</h5>
	<div class="row justify-content-md-center text-center">
    <div class="col-md centered" style="padding:1rem; margin-top:20px; ">
      <img src="./static/images/sub_module.png" style="width: 60%" class="img-responsive"/> 
    </div>
    <p class="text-muted" style="text-align:left; margin-left:15px"> 
      <strong>Multi-Modality integration</strong> with attention mechanisms. Self-attention uses the same input for Q, K, V. Cross-attention uses the cross-modality input for Q and K, V.
    </p> 
  </div>

</br>
<h5 class="section-subheading" style="text-align:left; margin-top:20px; color: rgb(100, 100, 100)">Mask Collaboration Module for task interaction</h5>
    <div class="row justify-content-md-center text-center">
    <div class="col-md centered" style="padding:1rem; margin-top:20px; ">
      <img src="./static/images/Mask_Collaborat_on_Module.png" style="width: 100%" class="img-responsive"/> 
    </div>
    <p class="text-muted" style="text-align:left; margin-left:15px"> 
      <strong>Mask Collaboration Module</strong> for task interaction. (a). The plain multi-task output without
      interaction. (b). Mask collaboration module introduces the interaction between these two tasks. As
      a fine-grained AVU task, region-aware visual information will give more details for text description.
      Thus, combining the multi-modal representations with more regional visual features will give more
      accurate fine-grained captions.
    </p>
  </div>
	  </div>
</section>

<!-- Results -->
<section id="results">
  <div class="col-md-12" style="text-align:left">
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center" style="margin-bottom: -50px; margin-top: -40px">
        <h2 class="section-heading" style="color: rgb(90, 90, 90); margin-top: 90px;margin-bottom:30px">Results</h2>
      </div>
    </div>
  </div>
</div>
<div class="col-md-12" style="text-align:left">
  <div class="container">
    <h5 class="section-subheading" style="text-align:left; margin-top:20px; color: rgb(100, 100, 100)">Demo Video</h5>
    <div class="row">
      <video controls class="d-block w-100">
        <source src="./static/videos/demo.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
    
    <!-- Carousel -->
    <h5 class="section-subheading" style="text-align:left; margin-top:50px; color: rgb(100, 100, 100)">Visual Results on f-music Dataset</h5>
    <div id="carouselExampleIndicators1" class="carousel slide">
      <ol class="carousel-indicators">
        <li data-target="#carouselExampleIndicators1" data-slide-to="0" class="active"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="1"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="2"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="3"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="4"></li>
      </ol>
      <div class="carousel-inner">
        <div class="carousel-item active">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/music1.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/music2.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/music3.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/music4.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/music5.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
            </div>
      <a class="carousel-control-prev" href="#carouselExampleIndicators1" role="button" data-slide="prev">
        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="carousel-control-next" href="#carouselExampleIndicators1" role="button" data-slide="next">
        <span class="carousel-control-next-icon" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
      </a>
    </div>

    <h5 class="section-subheading" style="text-align:left; margin-top:50px; color: rgb(100, 100, 100)">Visual Results on f-life Dataset</h5>
    <div id="carouselExampleIndicators1" class="carousel slide">
      <ol class="carousel-indicators">
        <li data-target="#carouselExampleIndicators1" data-slide-to="0" class="active"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="1"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="2"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="3"></li>
        <li data-target="#carouselExampleIndicators1" data-slide-to="4"></li>
      </ol>
      <div class="carousel-inner">
        <div class="carousel-item active">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/life1.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/life2.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/life3.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/life4.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
        <div class="carousel-item">
          <div class="d-flex justify-content-center">
            <div class="col-md-8">
              <video controls class="d-block w-100">
                <source src="./static/videos/life5.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
            </div>
      <a class="carousel-control-prev" href="#carouselExampleIndicators1" role="button" data-slide="prev">
        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
      </a>
      <a class="carousel-control-next" href="#carouselExampleIndicators1" role="button" data-slide="next">
        <span class="carousel-control-next-icon" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
      </a>
    </div>

  </div>
</div>
  </div>  
</section>

<!-- Experiments -->
 <section id="experiments">
  <div class="container">
    <div class="row">
      <div class="col-md-12 text-center">
        <h2 class="section-heading" style="color: rgb(90, 90, 90); margin-top: 60px">Experiments</h2>
        <h6 class="section-subheading" style="color: rgb(171, 171, 171)"> Extensive experiments are conducted on our two
          datasets to verify the feasibility of the task, evaluate the availability of the
          datasets, and demonstrate the superiority of the AVUFormer, which achieves
          SOTA performance on the Audio-Visual Understanding benchmark.
        </h6>
      </div>
    </div>
	
    <h5 class="section-subheading" style="text-align:left; color: rgb(100, 100, 100); margin-top: 50px">Quantitative comparisons with single-task models on dataset f-Music.</h5>
    <div class="row text-center">
      <p class="text-muted" style="text-align:left; margin-left:15px"> 
        SSS: Sound Source Segmentation,AVC: Audio-Visual Caption, AVU-D: Audio-Visual Understanding with Description Only, AVU-S: Audio-Visual Understanding with Segmentation Only.        
      </p>
    
      <img src="./static/images/e1.png" style="width: 85%; margin-left:30px;" class="img-responsive"/> 
    </div>
    <p class="text-muted" style="text-align:left; margin-left:50px; margin-top: 5px;"> 
      ↑ means the higher the better.  
      ↓ indicates the lower the better. <br> 
      “-” denotes that the method cannot be applied to the dataset due to the lack of text transcripts. <br> 
    </p>

    <h5 class="section-subheading" style="text-align:left; color: rgb(100, 100, 100); margin-top: 50px">Quantitative comparisons with single-task models on dataset f-Lifescene.</h5>
    <div class="row text-center">
      <p class="text-muted" style="text-align:left; margin-left:15px"> 
        SSS: Sound Source Segmentation,AVC: Audio-Visual Caption, AVU-D: Audio-Visual Understanding with Description Only, AVU-S: Audio-Visual Understanding with Segmentation Only.        
      </p>
    
      <img src="./static/images/e2.png" style="width: 85%; margin-left:30px;" class="img-responsive"/> 
    </div>
    <p class="text-muted" style="text-align:left; margin-left:50px; margin-top: 5px;"> 
      ↑ means the higher the better.  
      ↓ indicates the lower the better. <br> 
      “-” denotes that the method cannot be applied to the dataset due to the lack of text transcripts. <br> 
    </p>

    <h5 class="section-subheading" style="text-align:left; color: rgb(100, 100, 100); margin-top: 50px">Comparison with Multi-Model Large Models on sound object description task (average of two datasets).
      </h5>
    <div class="row text-center">
      <!-- <p class="text-muted" style="text-align:left; margin-left:15px"> 
        SSS: Sound Source Segmentation,AVC: Audio-Visual Caption, AVU-D: Audio-Visual Understanding with Description Only, AVU-S: Audio-Visual Understanding with Segmentation Only.        
      </p> -->
    
      <img src="./static/images/e3.png" style="width: 85%; margin-left:30px;" class="img-responsive"/> 
    </div>

    <h5 class="section-subheading" style="text-align:left; color: rgb(100, 100, 100); margin-top: 50px">Quantitative comparisons on ablation analysis.</h5>
    <div class="row text-center">
      <!-- <p class="text-muted" style="text-align:left; margin-left:15px"> 
        SSS: Sound Source Segmentation,AVC: Audio-Visual Caption, AVU-D: Audio-Visual Understanding with Description Only, AVU-S: Audio-Visual Understanding with Segmentation Only.        
      </p> -->
    
      <img src="./static/images/e4.png" style="width: 85%; margin-left:30px;" class="img-responsive"/> 
    </div>

  </div>
</section>

<div class="container">
  <div class="row">
    </div>
  </div>
</section>



<!-- <script type="application/ld+json">
{
  "@context":"http://schema.org/",
  "@type":"Dataset",
  "name":"LU-AVS dataset",
  "description":"First-person (egocentric) video dataset; multi-faceted non-scripted recordings in the wearers' homes, capturing all daily activities in the kitchen over multiple days. Annotations are collected using a novel live audio commentary approach.",
  "url":"https://github.com/epic-kitchens/annotations",
  "sameAs":"https://data.bris.ac.uk/data/dataset/3h91syskeag572hl6tvuovwv4d",
  "citation":"Damen, Dima et al. 'Scaling Egocentric Vision: The EPIC-KITCHENS Dataset', European Conference on Computer Vision, 2018",
  "identifier": "10.5523/bris.3h91syskeag572hl6tvuovwv4d",
  "keywords":[
     "Egocentric vision",
     "Human actions",
     "Object interactions",
     "actions",
     "video",
     "kitchens",
     "cooking",
     "dataset",
     "epic kitchens",
     "epic",
     "eccv",
     "2022"
  ],
  "creator":{
     "@type":"Organization",
     "url": "https://epic-kitchens.github.io/",
     "name":"EPIC Team",
     "contactPoint":{
        "@type":"ContactPoint",
        "contactType": "technical support",
        "email":"uob-epic-kitchens@bristol.ac.uk",
        "url":"https://github.com/epic-kitchens/annotations/issues"
     }
  },
  "distribution":[
     {
        "@type":"DataDownload",
        "encodingFormat":"video/mp4",
        "contentUrl":"https://data.bris.ac.uk/data/dataset/3h91syskeag572hl6tvuovwv4d"
     },
     {
        "@type":"DataDownload",
        "encodingFormat":"image/jpeg",
        "contentUrl":"https://data.bris.ac.uk/data/dataset/3h91syskeag572hl6tvuovwv4d"
     },
     {
        "@type":"DataDownload",
        "encodingFormat":"text/csv",
        "contentUrl":"https://github.com/epic-kitchens/annotations"
     },
     {
        "@type":"DataDownload",
        "encodingFormat":"application/octet-stream",
        "contentUrl":"https://github.com/epic-kitchens/annotations"
     }
  ],
  "license": "https://creativecommons.org/licenses/by-nc/4.0/"
}
</script> -->

    
<!-- Footer -->
    <footer style="background-color:#373435ff;margin-top:90px">
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <img alt="Creative Commons License" style="border-width:1px;float:left;margin-right:15px;margin-bottom:0px;" src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png"/>
            <span class="copyright" style="color:#eee;">Copyright &copy;  (Anonymous Now):</span>
          </div>
          <div class="col-md-8" style="text-align:right">
            <p style="color:#eee;">For any questions, email us at
              <a href="mailto:#"> anonymous</a></p>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="./jquery/jquery.min.js"></script>
    <script src="./jquery//bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="./jquery/jquery.easing.min.js"></script>
    <!-- Custom scripts for this template -->
    <script src="./jquery/agency.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
  </body>
</html>
